{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Homework Section 2: sklearn breast cancer data set\n",
    "\n",
    "In this section you will use many of the same classifiers used in Homework Section 1, applied to a small cancer dataset packaged with sklearn.  Unlike the simulated data, this dataset is greater than 2 dimensions, which means it will not be possible to easily visualize the decision boundaries.  Nevertheless, we can apply the same techniques. \n",
    "\n",
    "We provide several functions for visualizing the output of your classifiers (these are the same as in Homework Section 1).  You are encouraged to look at and edit these functions to get more familiar with matplotlib, but they should work without modification.\n",
    "\n",
    "Feel free to edit this notebook, but note that you will be using this notebook to solve your homework problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Instructions\n",
    "For the following questions, you will train your classifiers on:\n",
    "\n",
    "* original (raw) data\n",
    "* standardized data\n",
    "\n",
    "and observe how data data standardization affects the performance of different algorithms.\n",
    "\n",
    "> **NOTE:** You only have *ONE* attempt at each problem.  (The first two answers are already given to you in this notebook.)  These problems are not difficult, but please pay attention to what is being asked for.  Specifically, some questions ask for *TRAINING* accuracy while others ask for *TEST* accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# plot within the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# some plotting configurations\n",
    "matplotlib.rcParams['figure.figsize'] = (10,10)\n",
    "matplotlib.style.use('ggplot')\n",
    "matplotlib.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Inspect Data\n",
    "For this set of homework problems, you will use a small cancer data set which is included with sklearn.  To load this data, use:\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "```\n",
    "\n",
    "This data set contains 569 data points with 30 features and a binary target class.  You will need to split the data into training and validation sets.  To ensure your code matches the expected homework answers, set:\n",
    "\n",
    "```python\n",
    "test_size = 0.30\n",
    "random_state = 999\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import sklearn.model_selection as model\n",
    "\n",
    "# load the data from sklearn.datasets\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = model.train_test_split(cancer['data'],\n",
    "                                                        cancer['target'], \n",
    "                                                        test_size = 0.30, \n",
    "                                                        random_state = 999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.13</td>\n",
       "      <td>16.62</td>\n",
       "      <td>70.47</td>\n",
       "      <td>381.1</td>\n",
       "      <td>0.08151</td>\n",
       "      <td>0.03834</td>\n",
       "      <td>0.01369</td>\n",
       "      <td>0.01370</td>\n",
       "      <td>0.1511</td>\n",
       "      <td>0.06148</td>\n",
       "      <td>...</td>\n",
       "      <td>20.29</td>\n",
       "      <td>74.35</td>\n",
       "      <td>421.1</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.06219</td>\n",
       "      <td>0.04580</td>\n",
       "      <td>0.04044</td>\n",
       "      <td>0.2383</td>\n",
       "      <td>0.07083</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.87</td>\n",
       "      <td>16.21</td>\n",
       "      <td>88.52</td>\n",
       "      <td>593.7</td>\n",
       "      <td>0.08743</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>0.01502</td>\n",
       "      <td>0.02088</td>\n",
       "      <td>0.1424</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>25.58</td>\n",
       "      <td>96.74</td>\n",
       "      <td>694.4</td>\n",
       "      <td>0.1153</td>\n",
       "      <td>0.10080</td>\n",
       "      <td>0.05285</td>\n",
       "      <td>0.05556</td>\n",
       "      <td>0.2362</td>\n",
       "      <td>0.07113</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.91</td>\n",
       "      <td>21.02</td>\n",
       "      <td>124.40</td>\n",
       "      <td>994.0</td>\n",
       "      <td>0.12300</td>\n",
       "      <td>0.25760</td>\n",
       "      <td>0.31890</td>\n",
       "      <td>0.11980</td>\n",
       "      <td>0.2113</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>...</td>\n",
       "      <td>27.78</td>\n",
       "      <td>149.60</td>\n",
       "      <td>1304.0</td>\n",
       "      <td>0.1873</td>\n",
       "      <td>0.59170</td>\n",
       "      <td>0.90340</td>\n",
       "      <td>0.19640</td>\n",
       "      <td>0.3245</td>\n",
       "      <td>0.11980</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.66</td>\n",
       "      <td>19.13</td>\n",
       "      <td>89.46</td>\n",
       "      <td>575.3</td>\n",
       "      <td>0.09057</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.09657</td>\n",
       "      <td>0.04812</td>\n",
       "      <td>0.1848</td>\n",
       "      <td>0.06181</td>\n",
       "      <td>...</td>\n",
       "      <td>25.50</td>\n",
       "      <td>101.40</td>\n",
       "      <td>708.8</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.31670</td>\n",
       "      <td>0.36600</td>\n",
       "      <td>0.14070</td>\n",
       "      <td>0.2744</td>\n",
       "      <td>0.08839</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.43</td>\n",
       "      <td>19.63</td>\n",
       "      <td>85.84</td>\n",
       "      <td>565.4</td>\n",
       "      <td>0.09048</td>\n",
       "      <td>0.06288</td>\n",
       "      <td>0.05858</td>\n",
       "      <td>0.03438</td>\n",
       "      <td>0.1598</td>\n",
       "      <td>0.05671</td>\n",
       "      <td>...</td>\n",
       "      <td>29.87</td>\n",
       "      <td>116.60</td>\n",
       "      <td>993.6</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.26440</td>\n",
       "      <td>0.11600</td>\n",
       "      <td>0.2884</td>\n",
       "      <td>0.07371</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        11.13         16.62           70.47      381.1          0.08151   \n",
       "1        13.87         16.21           88.52      593.7          0.08743   \n",
       "2        17.91         21.02          124.40      994.0          0.12300   \n",
       "3        13.66         19.13           89.46      575.3          0.09057   \n",
       "4        13.43         19.63           85.84      565.4          0.09048   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.03834         0.01369              0.01370         0.1511   \n",
       "1           0.05492         0.01502              0.02088         0.1424   \n",
       "2           0.25760         0.31890              0.11980         0.2113   \n",
       "3           0.11470         0.09657              0.04812         0.1848   \n",
       "4           0.06288         0.05858              0.03438         0.1598   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.06148  ...          20.29            74.35       421.1   \n",
       "1                 0.05883  ...          25.58            96.74       694.4   \n",
       "2                 0.07115  ...          27.78           149.60      1304.0   \n",
       "3                 0.06181  ...          25.50           101.40       708.8   \n",
       "4                 0.05671  ...          29.87           116.60       993.6   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1030            0.06219          0.04580               0.04044   \n",
       "1            0.1153            0.10080          0.05285               0.05556   \n",
       "2            0.1873            0.59170          0.90340               0.19640   \n",
       "3            0.1147            0.31670          0.36600               0.14070   \n",
       "4            0.1401            0.15460          0.26440               0.11600   \n",
       "\n",
       "   worst symmetry  worst fractal dimension    y  \n",
       "0          0.2383                  0.07083  1.0  \n",
       "1          0.2362                  0.07113  1.0  \n",
       "2          0.3245                  0.11980  0.0  \n",
       "3          0.2744                  0.08839  1.0  \n",
       "4          0.2884                  0.07371  0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store training and validation data in pandas dataframes\n",
    "data_train = pd.DataFrame(np.c_[X_train, y_train],\n",
    "                                columns = np.append(cancer['feature_names'], ['y']))\n",
    "\n",
    "data_val = pd.DataFrame(np.c_[X_val, y_val],\n",
    "                              columns = np.append(cancer['feature_names'], ['y']))\n",
    "\n",
    "# look at the top 5 rows\n",
    "data_train.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "\n",
    "Notice that the columns in `X` represent real-valued quantities and are not all on the same scale.  Some features, such as \"mean smoothness\" average around 0.1, while others like \"mean area\" average in the hundreds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                 14.087786\n",
       "mean texture                18.945729\n",
       "mean perimeter              91.705678\n",
       "mean area                  651.046482\n",
       "mean smoothness              0.096132\n",
       "mean compactness             0.103100\n",
       "mean concavity               0.088261\n",
       "mean concave points          0.048117\n",
       "mean symmetry                0.180024\n",
       "mean fractal dimension       0.062805\n",
       "radius error                 0.404308\n",
       "texture error                1.203842\n",
       "perimeter error              2.865034\n",
       "area error                  39.912023\n",
       "smoothness error             0.006912\n",
       "compactness error            0.025281\n",
       "concavity error              0.032167\n",
       "concave points error         0.011767\n",
       "symmetry error               0.020372\n",
       "fractal dimension error      0.003813\n",
       "worst radius                16.166776\n",
       "worst texture               25.199472\n",
       "worst perimeter            106.584397\n",
       "worst area                 865.315829\n",
       "worst smoothness             0.131617\n",
       "worst compactness            0.249927\n",
       "worst concavity              0.268900\n",
       "worst concave points         0.112738\n",
       "worst symmetry               0.287877\n",
       "worst fractal dimension      0.083605\n",
       "y                            0.650754\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the mean values over the columns in the training set\n",
    "data_train.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardization** of datasets is a common requirement for many machine learning estimators implemented in scikit-learn; they might behave badly if the individual features do not more or less look like standard normally distributed data: **Gaussian with zero mean and unit variance.**\n",
    "\n",
    "To standardize your data (sometimes referred to as *normalizing* or *whitening*), you can take advantage of sklearn's [Preprocessing Package](http://scikit-learn.org/stable/modules/preprocessing.html).\n",
    "\n",
    "Below is an example of how to standardize your data based on sklearn's [RobustScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html), which normalizes the data to (approximately) zero-mean unit variance, while being more robust to outliers than the [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Preprocess the data to standardize using sklearn -- fit using training data only!\n",
    "scaler = preprocessing.RobustScaler().fit(X_train)\n",
    "\n",
    "# Store scaled versions of the data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                0.162705\n",
       "mean texture               0.068907\n",
       "mean perimeter             0.180144\n",
       "mean area                  0.271646\n",
       "mean smoothness            0.013820\n",
       "mean compactness           0.186763\n",
       "mean concavity             0.301924\n",
       "mean concave points        0.273592\n",
       "mean symmetry              0.069075\n",
       "mean fractal dimension     0.168009\n",
       "radius error               0.348586\n",
       "texture error              0.181777\n",
       "perimeter error            0.354393\n",
       "area error                 0.588212\n",
       "smoothness error           0.180468\n",
       "compactness error          0.262235\n",
       "concavity error            0.321169\n",
       "concave points error       0.145484\n",
       "symmetry error             0.207063\n",
       "fractal dimension error    0.298527\n",
       "worst radius               0.239386\n",
       "worst texture             -0.000709\n",
       "worst perimeter            0.225535\n",
       "worst area                 0.355672\n",
       "worst smoothness           0.013925\n",
       "worst compactness          0.179511\n",
       "worst concavity            0.161238\n",
       "worst concave points       0.137161\n",
       "worst symmetry             0.111464\n",
       "worst fractal dimension    0.206701\n",
       "y                          0.650754\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store training and validation data in pandas dataframes\n",
    "data_train_scaled = pd.DataFrame(np.c_[X_train_scaled, y_train],\n",
    "                                 columns= np.append(cancer['feature_names'], ['y']))\n",
    "\n",
    "data_val_scaled = pd.DataFrame(np.c_[X_val_scaled, y_val],\n",
    "                               columns= np.append(cancer['feature_names'], ['y']))\n",
    "\n",
    "# look at the mean values over the columns in the scaled training set\n",
    "data_train_scaled.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for training a generic sklearn classifier and plotting the results\n",
    "\n",
    "Here we provide some functions you may find helpful for training, evaluating and visualizing your classifiers.  You are encouraged to look at these functions to understand what they're doing, but they should work without modification.\n",
    "\n",
    "The function `train_and_plot()` takes in a sklearn classifier object, fits the model to training data, and evaluates the model on validation data.  This particular function assumes 2D data (defined by features x0_col and x1_col) and binary class labels (y = 0 or 1). \n",
    "\n",
    "The function `plot_data_class()` will create a 2D plot of data that has gone through a classifier.  If the original data (and therefore the classifier decision boundary) is also in 2D, it will also plot the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_class(data, x0_col=None, x1_col=None, xx=None, yy=None, Z=None, title='Classification Results'):\n",
    "    \"\"\"\n",
    "    Plot the classification results on data and the decision boundary \n",
    "    (Decision boundary will only be plotted if data is 2D)\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data :  pandas dataframe with columns = 'x_0', 'x_1', ... 'x_n', 'y', 'y_predict'\n",
    "            each row corresponds to a single data point\n",
    "                column 'x_n'       : nth feature \n",
    "                column 'y'         : true data label\n",
    "                column 'y_predict' : predicted data label\n",
    "                \n",
    "    x0_col: string corresponding to the x-axis feature\n",
    "    x1_col: string corresponding to the y-axis feature\n",
    "    \n",
    "    xx :    nd-array containing x-axis values for contour plot, must correspond to x0_col feature in data\n",
    "    yy :    nd-array containing y-axis values for contour plot, must correspond to x1_col feature in data\n",
    "            xx, yy = np.meshgrid()\n",
    "             \n",
    "    Z :     nd-array corresponding to classifier predictions of (xx,yy)\n",
    "            Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "            Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    title :  title of the plot (optional, default: 'Classification Results')\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # data features (exclude labels and predicted labels, if stored in the dataframe)\n",
    "    features = data.columns.difference(['y','y_predict'])\n",
    "    \n",
    "    # If no features are specified, use the first two\n",
    "    if x0_col is None: x0_col = features[0]\n",
    "    if x1_col is None: x1_col = features[1]\n",
    "    \n",
    "    # Separate the data into correctly and incorrectly classified sets\n",
    "    TP = data[(data['y']==1) & (data['y_predict']==1)]   # true positives\n",
    "    FP = data[(data['y']==0) & (data['y_predict']==1)]   # false positives (type I error)\n",
    "    TN = data[(data['y']==0) & (data['y_predict']==0)]   # true negatives\n",
    "    FN = data[(data['y']==1) & (data['y_predict']==0)]   # false negatives (type II error)\n",
    "\n",
    "    # Plot the contours if we're able (will pass if xx, yy, or Z are None)\n",
    "    try: plt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu,alpha=0.5)\n",
    "    except: pass\n",
    "        \n",
    "    # Plot the datapoints in 2D (actual data may be in higher dimension)\n",
    "    plt.scatter(TP[x0_col],TP[x1_col],marker='.',c='b',label='TP')\n",
    "    plt.scatter(TN[x0_col],TN[x1_col],marker='.',c='r',label='TN')\n",
    "    plt.scatter(FN[x0_col],FN[x1_col],marker='x',c='b',s=100,label='FN')\n",
    "    plt.scatter(FP[x0_col],FP[x1_col],marker='x',c='r',s=100,label='FP')\n",
    "    \n",
    "    plt.xlabel(x0_col)\n",
    "    plt.ylabel(x1_col)\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_plot(clf, data_train, data_test, plot_bool=True, x0_col=None, x1_col=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Train a classifier, evaluate, and plot\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    clf  :  a sklearn classifier object (e.g., sklearn.neighbors)\n",
    "    \n",
    "    data_train : pandas dataframe containing 2D training data\n",
    "                 each row corresponds to a single data point\n",
    "                        column 'y' : true label\n",
    "                        \n",
    "    data_test :  pandas dataframe containing 2D test data\n",
    "                 each row corresponds to a single data point\n",
    "                        column 'y' : true label\n",
    "                        \n",
    "    plot_bool :  boolean (default: True)\n",
    "                 set to False to suppress plots\n",
    "                 \n",
    "    x0_col :     name of first feature to plot, corresponding to a column in data_train\n",
    "                 if x0_col is not specified, the first column is used\n",
    "                 \n",
    "    x1_col :     name of second feature to plot, corresponding to a column in data_train\n",
    "                 if x1_col is not specified, the second column is used\n",
    "                 \n",
    "                  \n",
    "    Returns\n",
    "    -------\n",
    "    acc :   dictionary\n",
    "                'acc_train' : training accuracy\n",
    "                'acc_test'  : testing accuracy\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Define X (exclude labels and predicted labels, if stored in the dataframe)\n",
    "    X_train = data_train[data_train.columns.difference(['y','y_predict'])]\n",
    "    X_test = data_test[data_test.columns.difference(['y','y_predict'])]\n",
    "    \n",
    "    # Train (fit) the classifier to training data    \n",
    "    clf = clf.fit(X_train,data_train['y'])\n",
    "\n",
    "    # Apply the classifier to train and test data\n",
    "    data_train['y_predict'] = clf.predict(X_train)\n",
    "    data_test['y_predict'] = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate train and test accuracy\n",
    "    acc_train = clf.score(X_train,data_train['y'])\n",
    "    acc_test = clf.score(X_test,data_test['y'])\n",
    "    \n",
    "\n",
    "    # Plot the classification\n",
    "    if plot_bool:\n",
    "\n",
    "        if x0_col is None: x0_col = X_train.columns[0]\n",
    "        if x1_col is None: x1_col = X_train.columns[1]\n",
    "            \n",
    "            \n",
    "        # If we only have 2 features, we can make a contour plot by evaluating over a grid!  Otherwise, skip.\n",
    "        if X_train.shape[1] == 2:\n",
    "            \n",
    "            x_min = min(X_train[x0_col].min(),X_test[x0_col].min()) - 0.2\n",
    "            x_max = max(X_train[x0_col].max(),X_test[x0_col].max()) + 0.2\n",
    "            y_min = min(X_train[x1_col].min(),X_test[x1_col].min()) - 0.2\n",
    "            y_max = max(X_train[x1_col].max(),X_test[x1_col].max()) + 0.2\n",
    "\n",
    "            plot_step_x = (x_max-x_min)/100\n",
    "            plot_step_y = (y_max-y_min)/100\n",
    "            xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step_x),np.arange(y_min, y_max, plot_step_y))\n",
    "\n",
    "            # Predict on grid for contour plot\n",
    "            Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "            Z = Z.reshape(xx.shape)\n",
    "        else:\n",
    "            xx,yy,Z=None,None,None\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_data_class(data_train, x0_col, x1_col, xx, yy, Z, title='Train Data, acc={:0.3f}'.format(acc_train))\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_data_class(data_test, x0_col, x1_col, xx, yy, Z, title='Test Data, acc={:0.3f}'.format(acc_test))\n",
    "        plt.show()\n",
    "\n",
    "            \n",
    "        \n",
    "    return {'acc_train':acc_train, 'acc_test':acc_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW 2.1: Naive Bayes Training\n",
    "For the Naive Bayes classifier (with no priors), what happens to the **training** accuracy when the data is normalized?\n",
    "\n",
    "### HW 2.2: Naive Bayes Testing\n",
    "For the Naive Bayes classifier (with no priors), what happens to the **test** accuracy when the data is normalized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Original (unscaled) Data:\n",
      "   Training Accuracy: 0.952\n",
      "   Testing Accuracy:  0.936\n",
      "\n",
      " Scaled (normalized) Data:\n",
      "   Training Accuracy: 0.950\n",
      "   Testing Accuracy:  0.936\n"
     ]
    }
   ],
   "source": [
    "from sklearn import naive_bayes\n",
    "    \n",
    "# Define the classifier\n",
    "priors=None\n",
    "test = naive_bayes.GaussianNB(priors=priors)\n",
    "\n",
    "# Train the classifier\n",
    "acc_orig = train_and_plot(test, \n",
    "                          data_train, \n",
    "                          data_val, \n",
    "                          plot_bool=False,\n",
    "                          x0_col='worst compactness',\n",
    "                          x1_col='worst area')\n",
    "\n",
    "acc_norm = train_and_plot(test, \n",
    "                          data_train_scaled, \n",
    "                          data_val_scaled, \n",
    "                          plot_bool=False,\n",
    "                          x0_col='worst compactness', \n",
    "                          x1_col='worst area')\n",
    "\n",
    "# Print accuracy values\n",
    "print('\\n Original (unscaled) Data:')\n",
    "print('   Training Accuracy: {:0.3f}'.format(acc_orig['acc_train']))\n",
    "print('   Testing Accuracy:  {:0.3f}'.format(acc_orig['acc_test']))\n",
    "print('\\n Scaled (normalized) Data:')\n",
    "print('   Training Accuracy: {:0.3f}'.format(acc_norm['acc_train']))\n",
    "print('   Testing Accuracy:  {:0.3f}'.format(acc_norm['acc_test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW 2.3: Nearest Neighbor Training\n",
    "For the Nearest Neighbor classifier (with `n=2`), what happens to the **training** accuracy when the data is normalized?\n",
    "\n",
    "### HW 2.4: Nearest Neighbor Testing\n",
    "For the Nearest Neighbor classifier (with `n=2`), what happens to the **test** accuracy when the data is normalized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Original (unscaled) Data:\n",
      "   Training Accuracy: 0.975\n",
      "   Testing Accuracy:  0.936\n",
      "\n",
      " Scaled (normalized) Data:\n",
      "   Training Accuracy: 0.970\n",
      "   Testing Accuracy:  0.971\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "n_neighbors = 2\n",
    "\n",
    "# Define the classifier\n",
    "priors=None\n",
    "test = neighbors.KNeighborsClassifier(n_neighbors)\n",
    "\n",
    "acc_orig = train_and_plot(test, \n",
    "                          data_train, \n",
    "                          data_val, \n",
    "                          plot_bool=False,\n",
    "                          x0_col='worst compactness',\n",
    "                          x1_col='worst area')\n",
    "\n",
    "acc_norm = train_and_plot(test, \n",
    "                          data_train_scaled, \n",
    "                          data_val_scaled, \n",
    "                          plot_bool=False,\n",
    "                          x0_col='worst compactness', \n",
    "                          x1_col='worst area')\n",
    "\n",
    "# Print accuracy values\n",
    "print('\\n Original (unscaled) Data:')\n",
    "print('   Training Accuracy: {:0.3f}'.format(acc_orig['acc_train']))\n",
    "print('   Testing Accuracy:  {:0.3f}'.format(acc_orig['acc_test']))\n",
    "print('\\n Scaled (normalized) Data:')\n",
    "print('   Training Accuracy: {:0.3f}'.format(acc_norm['acc_train']))\n",
    "print('   Testing Accuracy:  {:0.3f}'.format(acc_norm['acc_test']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW 2.5: Decision Tree Training\n",
    "For the Decision Tree classifier (with max_depth = 6), what happens to the **training** accuracy when the data is normalized?\n",
    "\n",
    "### HW 2.6: Decision Tree Testing\n",
    "For the Decision Tree classifier (with max_depth = 6), what happens to the **test** accuracy when the data is normalized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "max_depth = 6\n",
    "random_state = 999\n",
    "\n",
    "test = tree.DecisionTreeClassifier(max_depth = 6, random_state = 999)\n",
    "\n",
    "acc_orig = train_and_plot(test, \n",
    "                          data_train, \n",
    "                          data_val, \n",
    "                          plot_bool=False,\n",
    "                          x0_col='worst compactness',\n",
    "                          x1_col='worst area')\n",
    "\n",
    "acc_norm = train_and_plot(test, \n",
    "                          data_train_scaled, \n",
    "                          data_val_scaled, \n",
    "                          plot_bool=False,\n",
    "                          x0_col='worst compactness', \n",
    "                          x1_col='worst area')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW 2.7: SVM Accuracy - Default Parameters with Unnormalized Data\n",
    "For the Support Vector Machine classifier with RBF kernel and default parameter values (`C=1.0, gamma='auto'`), what accuracy does sklearn produce when the data is **NOT** normalized?\n",
    "\n",
    "### HW 2.8: SVM Accuracy - Default Parameters with Normalized Data\n",
    "For the Support Vector Machine classifier with RBF kernel and default parameter values (`C=1.0, gamma='auto'`), what accuracy does sklearn produce when the data **IS** normalized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm   \n",
    "\n",
    "kernel='rbf'\n",
    "gamma='auto'\n",
    "C=1.0\n",
    "random_state = 999\n",
    "\n",
    "# Student code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine Parameters\n",
    "Finding good parameters for a support vector classification is an art.  The sklearn SVC default values for $C$ and $\\gamma$ can occasionally be used, but often you will need to do a parameter search to parameters that will work well on your data.\n",
    "\n",
    "The code below plots a heatmap of validation accuracies for varying values of $C$ and $\\gamma$ using the RBF kernel (white=high, black=low).  Notice that for this data set (un-normalized), the \"best\" parameter values are around $C \\approx 2.5$ and $\\gamma \\approx 0.0005$.  (As we will see later, these parameters may not be optimal for the normalized data.)\n",
    "\n",
    "Note: Running this code may take a little while, so we output the progress within the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00% complete... \n",
      "08% complete... \n",
      "15% complete... \n",
      "23% complete... \n",
      "31% complete... \n",
      "38% complete... \n",
      "46% complete... \n",
      "54% complete... \n",
      "62% complete... \n",
      "69% complete... \n",
      "77% complete... \n",
      "85% complete... \n",
      "92% complete... \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn4AAAFvCAYAAADUssbDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa30f0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import svm   \n",
    "\n",
    "# Define the values for C and gamma we wish to evaluate\n",
    "crange = np.arange(0.5,7.0,0.5)\n",
    "grange = np.arange(0.00005,0.00155,0.00005)\n",
    "a = np.zeros((crange.shape[0],grange.shape[0]))\n",
    "\n",
    "\n",
    "# Sweep through our parameters and calculate test accuracy at each value\n",
    "for cind in range(crange.size):\n",
    "    \n",
    "    # Print our current progress\n",
    "    print('{:02.0f}% complete... '.format(cind/crange.size*100))\n",
    "    \n",
    "    for gind in range(grange.size):\n",
    "        \n",
    "        # Train a classifier at the current parameter values\n",
    "        clf = svm.SVC(C=crange[cind],kernel='rbf',gamma=grange[gind],random_state=999)\n",
    "        acc = train_and_plot(clf, data_train, data_val, plot_bool=False)\n",
    "        \n",
    "        # store the accuracy in an numpy.ndarray\n",
    "        a[cind,gind] = acc['acc_test']\n",
    "    \n",
    "\n",
    "# Plot heatmap of accuracy values\n",
    "plt.imshow(a, cmap='hot', interpolation='nearest')\n",
    "plt.title(r'RBF SVM Validation Accuracy for Varying C and $\\gamma$')\n",
    "ax = plt.gca()\n",
    "ax.set_xticks(np.arange(1,grange.size,2))\n",
    "ax.set_yticks(np.arange(crange.size))\n",
    "ax.set_xticklabels(grange[1:grange.size:2], rotation = 60)\n",
    "ax.set_yticklabels(crange)\n",
    "ax.set_xlabel(r'$\\gamma$')\n",
    "ax.set_ylabel('C')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW 2.9: SVM - Effects of Data Normalization\n",
    "For the Support Vector Machine classifier with RBF kernel and parameter values (`C=2.5, gamma=0.0005`), what happens to the **test** accuracy when the data is normalized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel='rbf'\n",
    "gamma=0.0005\n",
    "C=2.5\n",
    "random_state = 999\n",
    "\n",
    "# Student code goes here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
